<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Yash Bhalgat</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/yash_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yash Sanjay Bhalgat</name>
              </p>
              <p>I am a research scientist at <a href="https://www.qualcomm.com/invention/artificial-intelligence/ai-research">Qualcomm AI Research</a>. I do algorithm and system design to develop efficient deep networks for computer vision use-cases.
              </p>
	      <p>
	      I have developed pipelines and published papers on low-bit quantization [<a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w40/Bhalgat_LSQ_Improving_Low-Bit_Quantization_Through_Learnable_Offsets_and_Better_Initialization_CVPRW_2020_paper.html">LSQ+</a>, <a href="https://arxiv.org/abs/1911.12491">QKD</a>], structured [<a href="https://arxiv.org/abs/2008.02454">StructConv</a>] and unstructured pruning [<a href="https://arxiv.org/pdf/2003.00075.pdf">LTP</a>] of deep networks. The usecases I have worked on include image and video classification / segmentation, pose estimation, gaze estimation, etc. My current research focuses on developing <b>compute-adaptive deep networks</b>.
	      </p>
	      <p>
	      I graduated with Masters in Computer Science from the <a href="https://cse.engin.umich.edu/academics/undergraduate/computer-science-eng/">University of Michigan, Ann Arbor</a>. I majored in Electrical Engineering and minored in Computer Science from <a href="http://iitb.ac.in/">Indian Institute of Technology (IIT), Bombay</a>.
	      </p>
              <p style="text-align:center">
                <a href="mailto:yashbhalgat95@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_YashBhalgat.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=q0VSEHYAAAAJ">Google Scholar</a> &nbsp/&nbsp
		<a href="https://github.com/yashbhalgat">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yashbhalgat/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://www.instagram.com/yashbhalgat.music">Music</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YashBhalgat_DP.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/YashBhalgat_DP.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
	      <ul>
		  <li><a href="https://arxiv.org/abs/2008.02454">StructConv</a> paper in accepted in NeurIPS 2020! &#128522;</li>
		  <li>Preprint for my work "Structured Convolutions for Efficient Neural Network Design" available on <a href="https://arxiv.org/abs/2008.02454">arxiv</a>! Check it out.</li>
		  <li>LSQ+ <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w40/Bhalgat_LSQ_Improving_Low-Bit_Quantization_Through_Learnable_Offsets_and_Better_Initialization_CVPRW_2020_paper.html">paper</a> accepted to the Efficient Deep Learning in Computer Vision workshop at CVPR 2020</li>
                  <li>3rd position in the NeurIPS 2019 MicroNet competition ImageNet track!! - <a href="https://micronet-challenge.github.io/leaderboard.html">Leaderboard</a>. Code is available <a href="https://github.com/yashbhalgat/QualcommAI-MicroNet-submission-MixNet">here</a> and <a href="https://github.com/yashbhalgat/QualcommAI-MicroNet-submission-EfficientNet">here</a>.</li>
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
	    </td>
	  </tr>
	</table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr onmouseout="struct_stop()" onmouseover="struct_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='struct_image'>
                  <img src='images/struct.PNG' width=240></div>
                <img src='images/struct_other.PNG' width=240>
              </div>
              <script type="text/javascript">
                function struct_start() {
                  document.getElementById('struct_image').style.opacity = "1";
                }

                function struct_stop() {
                  document.getElementById('struct_image').style.opacity = "0";
                }
                struct_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
		    <a href="https://arxiv.org/pdf/2008.02454.pdf"><papertitle>Structured Convolutions for Efficient Neural Network Design</papertitle></a>
              <br>
	      <strong>Yash Bhalgat</strong>,
              <a href="https://scholar.google.com/citations?user=u93s1AUAAAAJ&hl=en">Yizhe Zhang</a>,
              <a href="https://www.linkedin.com/in/jmjlin">Jamie Lin</a>,
              <a href="http://www.porikli.com/">Fatih Porikli</a>,
              <br>
        <em>NeurIPS</em>, 2020  
              <br>
              <p>We introduce a neat trick to enable the execution of convolution operations in the form of efficient, scaled, sum-pooling components. We present a Structural Regularization loss that enables this decomposition with negligible performance loss. Our method is competitive with other tensor decomposition and structured pruning methods.</p>
            </td>
          </tr>
	
          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/lsq_plus.png' width=240></div>
                <img src='images/lsq_plus_other.png' width=240>
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
		    <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Bhalgat_LSQ_Improving_Low-Bit_Quantization_Through_Learnable_Offsets_and_Better_Initialization_CVPRW_2020_paper.pdf"><papertitle>LSQ+: Improving low-bit quantization through learnable offsets and better initialization</papertitle></a>
              <br>
	      <strong>Yash Bhalgat</strong>,
              <a href="https://www.linkedin.com/in/jinwon-lee-6ba13a7">Jinwon Lee</a>,
              <a href="https://scholar.google.com/citations?user=akNuBBEAAAAJ&hl=en">Markus Nagel</a>,
              <a href="https://scholar.google.com/citations?user=OGEyrG8AAAAJ&hl=en">Tijmen Blankevoort</a>,
              <a href="https://scholar.google.com/citations?user=h_8-1M0AAAAJ&hl=en">Nojun Kwak</a>,
              <br>
        <em>Efficient Deep Learning in Computer Vision Workshop, CVPR</em>, 2020  
              <br>
              <p>We introduce a general asymmetric quantization scheme with trainable scale and offset parameters. LSQ+ shows SOTA results for EfficientNet and MixNet outperforming LSQ for low-bit quantization.</p>
            </td>
          </tr>
          
	  <tr onmouseout="ltp_stop()" onmouseover="ltp_start()">
	    <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ltp_image'>
                  <img src='images/ltp.png' width=240></div>
                <img src='images/ltp_other.png' width=240>
              </div>
              <script type="text/javascript">
                function ltp_start() {
                  document.getElementById('ltp_image').style.opacity = "1";
                }

                function ltp_stop() {
                  document.getElementById('ltp_image').style.opacity = "0";
                }
                ltp_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2003.00075"><papertitle>Learned Threshold Pruning</papertitle></a>
              <br>
	      <a href="https://dblp.uni-trier.de/pers/a/Azarian:Kambiz.html">Kambiz Azarian</a>,
              <strong>Yash Bhalgat</strong>,
              <a href="https://www.linkedin.com/in/jinwon-lee-6ba13a7">Jinwon Lee</a>,
              <a href="https://scholar.google.com/citations?user=OGEyrG8AAAAJ&hl=en">Tijmen Blankevoort</a>
              <br>
	      <em><a href="https://arxiv.org/pdf/2003.00075">arxiv</a></em>, 2020
              <br>
	      <p>We propose an end-to-end differentiable method for learning layerwise pruning thresholds which results in SOTA model compression ratios with AlexNet, ResNet and EfficientNet. Our method also generates a trail of checkpoints with different accuracy-efficiency operating points.</p>
            </td>
          </tr>

	  <tr onmouseout="qkd_stop()" onmouseover="qkd_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='qkd_image'>
                  <img src='images/qkd.png' width=240></div>
                <img src='images/qkd_other.png' width=240>
              </div>
              <script type="text/javascript">
                function qkd_start() {
                  document.getElementById('qkd_image').style.opacity = "1";
                }

                function qkd_stop() {
                  document.getElementById('qkd_image').style.opacity = "0";
                }
                qkd_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/1911.12491"><papertitle>QKD: Quantization-aware Knowledge Distillation for Low-bit Quantization</papertitle></a>
              <br>
              <strong>Yash Bhalgat*</strong>,
	      <a href="https://scholar.google.co.kr/citations?user=mzFEJVIAAAAJ&hl=ko">Jangho Kim*</a>,
              <a href="https://www.linkedin.com/in/jinwon-lee-6ba13a7">Jinwon Lee</a>,
              <a href="https://www.linkedin.com/in/chirag-patel-b0a6921/">Chirag Patel</a>,
	      <a href="https://scholar.google.co.kr/citations?user=h_8-1M0AAAAJ&hl=ko">Nojun Kwak</a>
              <br>
              <em><a href="https://arxiv.org/abs/1911.12491">arxiv</a></em>, 2020
              <br>
	      <p>Low-bit quantization and KD often don't go well together, but both are important approaches to reduces a model's memory footprint. We propose an effective method to combine these two methods and show results that outperform all existing quantization/KD approaches.</p>
            </td>
          </tr>

          <tr onmouseout="ibm_stop()" onmouseover="ibm_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ibm_image'>
                  <img src='images/ibm.png' width=240></div>
                <img src='images/ibm.png' width=240>
              </div>
              <script type="text/javascript">
                function ibm_start() {
                  document.getElementById('ibm_image').style.opacity = "1";
                }

                function ibm_stop() {
                  document.getElementById('ibm_image').style.opacity = "0";
                }
                ibm_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://konvens.org/proceedings/2019/papers/KONVENS2019_paper_52.pdf"><papertitle>Teacher-Student Learning Paradigm for Tri-training: An Efficient
Method for Unlabeled Data Exploitation</papertitle></a>
              <br>
              <strong>Yash Bhalgat</strong>,
              <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-liuzh">Zhe Liu</a>,
              <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-psgundec">Pritam Gundecha</a>,
              <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-jumahmud">Jalal Mahmud</a>,
              <a href="https://www.linkedin.com/in/amita-misra/">Amita Misra</a>
              <br>
              <em>KONVENS</em>, 2019
              <br>
	      <p>Teacher-student tri-training is a method for semi-supervised learning using 3 classifiers working using adaptive teacher and student thresholds.</p>
            </td>
          </tr>

	  <tr onmouseout="sms_stop()" onmouseover="sms_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sms_image'>
                  <img src='images/sms.png' width=200></div>
                <img src='images/sms.png' width=200>
              </div>
              <script type="text/javascript">
                function sms_start() {
                  document.getElementById('sms_image').style.opacity = "1";
                }

                function sms_stop() {
                  document.getElementById('sms_image').style.opacity = "0";
                }
                sms_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/1812.11302.pdf"><papertitle>Annotation-cost Minimization for Medical Image Segmentation using Suggestive Mixed Supervision Fully Convolutional Networks</papertitle></a>
              <br>
              <strong>Yash Bhalgat*</strong>,
              <a href="https://meetshah1995.github.io/">Meet Shah*</a>
              <a href="https://www.cse.iitb.ac.in/~suyash/">Suyash Awate</a>,
              <br>
              <em>Medical Imaging meets NeurIPS workshop</em>, 2019
              <br>
              <p>For Medical Image segmentation, we present a budget-based cost-minimization framework in a mixed-supervision setting via dense segmentations, bounding boxes, and landmarks.</p>
            </td>
          </tr>

          <tr onmouseout="icassp_stop()" onmouseover="icassp_start()">
            <td style="padding:20px;width:33%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icassp_image'>
                  <img src='images/icassp.png' width=200></div>
                <img src='images/icassp_other.png' width=200>
              </div>
              <script type="text/javascript">
                function icassp_start() {
                  document.getElementById('icassp_image').style.opacity = "1";
                }

                function icassp_stop() {
                  document.getElementById('icassp_image').style.opacity = "0";
                }
                icassp_stop()
              </script>
            </td>
            <td style="padding:20px;width:67%;vertical-align:middle">
                    <a href="https://ieeexplore.ieee.org/abstract/document/8462088"><papertitle>CATSEYES: Categorizing Seismic structures with tessellated scattering wavelet networks</papertitle></a>
              <br>
              <strong>Yash Bhalgat</strong>,
              <a href="https://ieeexplore.ieee.org/author/37086455393">Jean Charlety</a>,
              <a href="https://ieeexplore.ieee.org/author/37285084800">Laurent Duval</a>
              <br>
              <em>ICASSP</em>, 2018
              <br>
              <p>We use Scattering Wavelets transforms to extract sparse feature sets from seismic data. We show that using this method combined with simple PCA-based feature selection leads to promising classification performance in affordable computation time.</p>
            </td>
          </tr>

	</tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Hall of Fame</heading>
              <p>
              <ul>
		  <li>All India Rank <b>12</b> in IITJEE-Mains 2013 exam among 1.5 million students</li>
		  <li>All India Rank <b>155</b> in IITJEE-Advanced 2013 exam among 0.2 million students</li>
		  <li>Featured in National Top 30 for the International Astronomy Olympiad, 2013</li>
		  <li>Secured All India Rank 60 and awarded the KVPY Scholarship by Govt. of India</li>
		  <li>Among top 300 in India to compete in the Physics, Chemistry and Mathematics olympiads</li>
		  <li>Awarded Cargill Global Scholarship 2014-15 and selected in the 10-member Indian cohort to represent at the global seminar in Minneapolis, USA in 2016</li>
		  <li>Received the Undergraduate Research Award (URA02) for my Bachelors thesis at IIT Bombay</li>
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Music</heading>
	      <p>To get away from my exciting yet stressful life as a computer scientist, I indulge myself into the realms of music. I spent my entire childhood learning Tabla, an Indian percussion instrument. I briefly also tried to learn the Piano, Drums and Harmonia but had to leave that for my higher studies. One day, I naturally started beatboxing (<a href="https://youtu.be/0ZfSStpZPfI">check this out</a>) and I continue that passion to this day. Please checkout my music channels that I try to maintain regularly. :)</p>
	      <ul>
		  <li><a href="https://www.instagram.com/yashbhalgat.music/">Instagram Music Channel</a></li>
		  <li><a href="https://m.youtube.com/c/YashBhalgat">YouTube Music Channel</a></li>
	      </ul>
            </td>
	    <td style="padding:0px;width:50%;vertical-align:right">
                  <img src='images/big_tabla.jpg' width=300></div>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
	      Website template borrowed from <a href="https://jonbarron.info">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
